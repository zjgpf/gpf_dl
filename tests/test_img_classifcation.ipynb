{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.pardir)\n",
    "import core,model\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pdb\n",
    "import torch.tensor as tensor\n",
    "from matplotlib import pyplot as plt\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index_img_c = {'frog':0,'truck':1,'deer':2,'automobile':3,'bird':4,'horse':5,'ship':6,'cat':7,'airplane':8,'dog':9}\n",
    "train_path = '/data/gpf/tutorial/dl/cnn/cifar/train'\n",
    "test_path = '/data/gpf/tutorial/dl/cnn/cifar/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog:5000\n",
      "truck:5000\n",
      "deer:5000\n",
      "automobile:5000\n",
      "bird:5000\n",
      "horse:5000\n",
      "ship:5000\n",
      "cat:5000\n",
      "airplane:5000\n",
      "dog:5000\n"
     ]
    }
   ],
   "source": [
    "path_labels_train = core.get_img_path_label_from_path(train_path,label_index_img_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog:1000\n",
      "truck:1000\n",
      "deer:1000\n",
      "automobile:1000\n",
      "bird:1000\n",
      "horse:1000\n",
      "ship:1000\n",
      "cat:1000\n",
      "airplane:1000\n",
      "dog:1000\n"
     ]
    }
   ],
   "source": [
    "path_labels_test = core.get_img_path_label_from_path(test_path,label_index_img_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths, labels = zip(*path_labels_train)\n",
    "#dl = core.make_batches_img(np.array(img_paths), np.array(labels).astype(int),bs=64)\n",
    "dl = core.dl_img(np.array(img_paths), np.array(labels).astype(int),bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    }
   ],
   "source": [
    "a = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9e61b0080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((a[0][0].numpy()).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=3072, out_features=40, bias=True)\n",
       "    (1): Linear(in_features=40, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[32*32*3, 40,10]\n",
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(layers[i],layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        bs = seq.size()[0]\n",
    "        X = seq.view(bs,-1)\n",
    "        for layer in self.layers:\n",
    "            X = F.relu(layer(X))\n",
    "        return F.log_softmax(X,dim=-1)\n",
    "    \n",
    "    def get_device(self):\n",
    "        p = next(self.parameters())\n",
    "        device_type = str(p.device.type)\n",
    "        device_index = p.device.index\n",
    "        ret = device_type + ':' + str(device_index) if device_type == 'cuda' else device_type\n",
    "        return torch.device(ret) \n",
    "    \n",
    "\n",
    "m = SimpleNet([32*32*3,40,10]).cuda()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(m.parameters(),lr=0.1,momentum=0.5)\n",
    "loss_fn = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is been trained on cuda:1\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:04<00:44,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, total loss: 1522.6445281505585\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:09<00:39,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total loss: 1458.159904718399\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:14<00:34,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, total loss: 1437.8746687173843\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:19<00:29,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, total loss: 1440.5406029224396\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:24<00:24,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, total loss: 1415.5925860404968\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:28<00:19,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, total loss: 1399.5946494340897\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:33<00:14,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, total loss: 1385.917455792427\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:38<00:09,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, total loss: 1374.4950954914093\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:43<00:04,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, total loss: 1377.2594555616379\n",
      "Making batches... batch size: 64,num of batchese: 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:47<00:00,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, total loss: 1368.1898460388184\n",
      "Saving model to /data/gpf/gpf_dl/tests/tmp_torch_model.torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "core.fit(m,dl,10,opt,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths, labels = zip(*path_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths, labels = zip(*path_labels_test)\n",
    "dl = core.dl_img(np.array(img_paths), np.array(labels).astype(int),bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making batches... batch size: 64,num of batchese: 157\n"
     ]
    }
   ],
   "source": [
    "imgs,labels = zip(*dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = core.predict_batch_img(m,imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expects = []\n",
    "a = [expects.extend(v.tolist()) for v in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------0-------------------------------\n",
      "total:  1000\n",
      "correct:  1000\n",
      "accuracy:  1.0\n",
      "---------------------------1-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------2-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------3-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------4-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------5-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------6-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------7-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------8-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------9-------------------------------\n",
      "total:  1000\n",
      "correct:  0\n",
      "accuracy:  0.0\n",
      "---------------------------All-------------------------------\n",
      "total correct/total:1000/10000\n",
      "total accuracy:  0.1\n"
     ]
    }
   ],
   "source": [
    "core.evaluation_matrix(np.array(preds),np.array(expects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1976.440\n",
      "[1,  4000] loss: 59.830\n",
      "[1,  6000] loss: 17.826\n",
      "[1,  8000] loss: 9.478\n",
      "[1, 10000] loss: 5.936\n",
      "[1, 12000] loss: 5.227\n",
      "[2,  2000] loss: 3.812\n",
      "[2,  4000] loss: 2.746\n",
      "[2,  6000] loss: 2.778\n",
      "[2,  8000] loss: 2.584\n",
      "[2, 10000] loss: 2.968\n",
      "[2, 12000] loss: 2.463\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = m(inputs.to(torch.device('cuda:1')))\n",
    "        loss = loss_fn(outputs, labels.to(torch.device('cuda:1')))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 58 %\n",
      "Accuracy of   car : 64 %\n",
      "Accuracy of  bird :  7 %\n",
      "Accuracy of   cat : 28 %\n",
      "Accuracy of  deer : 25 %\n",
      "Accuracy of   dog : 17 %\n",
      "Accuracy of  frog : 62 %\n",
      "Accuracy of horse : 58 %\n",
      "Accuracy of  ship : 32 %\n",
      "Accuracy of truck :  1 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = m(images.to(torch.device('cuda:1')))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels.to(torch.device('cuda:1'))).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 35 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = m(images.to(torch.device('cuda:1')))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(torch.device('cuda:1'))).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
